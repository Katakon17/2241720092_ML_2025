{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e927c82",
   "metadata": {},
   "source": [
    "# Tugas Praktikum: Klasifikasi MNIST dengan JST\n",
    "\n",
    "Menggunakan Jaringan Saraf Tiruan (JST) untuk klasifikasi angka tulisan tangan (MNIST).\n",
    "\n",
    "## Langkah:\n",
    "1. Load dataset MNIST dari Keras\n",
    "2. Bangun model dengan 2 hidden layer\n",
    "3. Latih model dan evaluasi akurasi\n",
    "4. Eksperimen dengan berbagai parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8675d4",
   "metadata": {},
   "source": [
    "## 1. Load Dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32853583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET MNIST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nShape data training: {X_train.shape}\")\n",
    "print(f\"Shape data testing: {X_test.shape}\")\n",
    "print(f\"Ukuran gambar: {X_train.shape[1]}x{X_train.shape[2]} pixels\")\n",
    "print(f\"Jumlah kelas: 10 (digit 0-9)\")\n",
    "\n",
    "# Visualisasi beberapa sampel\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {y_train[i]}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Contoh Gambar MNIST', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi data (0-255 â†’ 0-1)\n",
    "X_train_norm = X_train / 255.0\n",
    "X_test_norm = X_test / 255.0\n",
    "\n",
    "# One-hot encoding label\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSebelum normalisasi - Min: {X_train.min()}, Max: {X_train.max()}\")\n",
    "print(f\"Sesudah normalisasi - Min: {X_train_norm.min():.2f}, Max: {X_train_norm.max():.2f}\")\n",
    "print(f\"\\nContoh one-hot encoding:\")\n",
    "print(f\"Label asli: {y_train[0]}\")\n",
    "print(f\"One-hot: {y_train_cat[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aacabd",
   "metadata": {},
   "source": [
    "## 2. Bangun Model JST dengan 2 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bangun model JST dengan 2 hidden layer\n",
    "model = Sequential([\n",
    "    # Ubah gambar 28x28 menjadi vektor 784\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    \n",
    "    # Hidden layer 1: 128 neuron, aktivasi ReLU\n",
    "    Dense(128, activation='relu'),\n",
    "    \n",
    "    # Hidden layer 2: 64 neuron, aktivasi ReLU\n",
    "    Dense(64, activation='relu'),\n",
    "    \n",
    "    # Output layer: 10 kelas (digit 0-9), aktivasi softmax\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Tampilkan arsitektur model\n",
    "print(\"=\" * 60)\n",
    "print(\"ARSITEKTUR MODEL JST\")\n",
    "print(\"=\" * 60)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3994f",
   "metadata": {},
   "source": [
    "## 3. Kompilasi dan Latih Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab41d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Kompilasi model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"KOMPILASI MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Optimizer: Adam\")\n",
    "print(\"Loss function: Categorical Crossentropy\")\n",
    "print(\"Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f458170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Latih model\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_norm, y_train_cat,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nWaktu training: {training_time:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac8039",
   "metadata": {},
   "source": [
    "## 4. Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Evaluasi model pada data uji\n",
    "loss, acc = model.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUASI MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLoss pada data uji: {loss:.4f}\")\n",
    "print(f\"Akurasi pada data uji: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "# Visualisasi training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[1].set_title('Training & Validation Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eebebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi beberapa sampel\n",
    "predictions = model.predict(X_test_norm[:10])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Visualisasi prediksi\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(X_test[i], cmap='gray')\n",
    "    color = 'green' if predicted_labels[i] == y_test[i] else 'red'\n",
    "    ax.set_title(f'Pred: {predicted_labels[i]}, True: {y_test[i]}', color=color)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Hasil Prediksi (Hijau=Benar, Merah=Salah)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d91d6d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Eksperimen dengan Berbagai Parameter\n",
    "\n",
    "### Eksperimen 1: Ubah jumlah neuron (256 dan 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EKSPERIMEN 1: Model dengan 256 dan 128 neuron\n",
    "# ============================================================\n",
    "\n",
    "model_exp1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),   # Hidden layer 1: 256 neuron\n",
    "    Dense(128, activation='relu'),   # Hidden layer 2: 128 neuron\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_exp1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EKSPERIMEN 1: Model dengan 256 dan 128 neuron\")\n",
    "print(\"=\" * 60)\n",
    "model_exp1.summary()\n",
    "\n",
    "start_time = time.time()\n",
    "history_exp1 = model_exp1.fit(X_train_norm, y_train_cat, epochs=10, batch_size=32, \n",
    "                               validation_split=0.1, verbose=1)\n",
    "time_exp1 = time.time() - start_time\n",
    "\n",
    "loss_exp1, acc_exp1 = model_exp1.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"\\nâœ… Hasil Eksperimen 1:\")\n",
    "print(f\"   Akurasi: {acc_exp1:.4f} ({acc_exp1*100:.2f}%)\")\n",
    "print(f\"   Waktu training: {time_exp1:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b78a8",
   "metadata": {},
   "source": [
    "### Eksperimen 2: Tambah satu hidden layer lagi (3 hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5abfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EKSPERIMEN 2: Model dengan 3 hidden layer\n",
    "# ============================================================\n",
    "\n",
    "model_exp2 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),   # Hidden layer 1\n",
    "    Dense(128, activation='relu'),   # Hidden layer 2\n",
    "    Dense(64, activation='relu'),    # Hidden layer 3 (tambahan)\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_exp2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EKSPERIMEN 2: Model dengan 3 Hidden Layer\")\n",
    "print(\"=\" * 60)\n",
    "model_exp2.summary()\n",
    "\n",
    "start_time = time.time()\n",
    "history_exp2 = model_exp2.fit(X_train_norm, y_train_cat, epochs=10, batch_size=32, \n",
    "                               validation_split=0.1, verbose=1)\n",
    "time_exp2 = time.time() - start_time\n",
    "\n",
    "loss_exp2, acc_exp2 = model_exp2.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"\\nâœ… Hasil Eksperimen 2:\")\n",
    "print(f\"   Akurasi: {acc_exp2:.4f} ({acc_exp2*100:.2f}%)\")\n",
    "print(f\"   Waktu training: {time_exp2:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5dc04",
   "metadata": {},
   "source": [
    "### Eksperimen 3: Perbandingan Sigmoid vs ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EKSPERIMEN 3: Perbandingan Sigmoid vs ReLU\n",
    "# ============================================================\n",
    "\n",
    "# Model dengan Sigmoid\n",
    "model_sigmoid = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model dengan ReLU\n",
    "model_relu = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EKSPERIMEN 3: SIGMOID vs ReLU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training Sigmoid\n",
    "print(\"\\nðŸ”¹ Training model dengan SIGMOID...\")\n",
    "start_sigmoid = time.time()\n",
    "history_sigmoid = model_sigmoid.fit(X_train_norm, y_train_cat, epochs=10, batch_size=32, \n",
    "                                     validation_split=0.1, verbose=0)\n",
    "time_sigmoid = time.time() - start_sigmoid\n",
    "loss_sigmoid, acc_sigmoid = model_sigmoid.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"   Akurasi: {acc_sigmoid:.4f}, Waktu: {time_sigmoid:.2f}s\")\n",
    "\n",
    "# Training ReLU\n",
    "print(\"\\nðŸ”¹ Training model dengan ReLU...\")\n",
    "start_relu = time.time()\n",
    "history_relu = model_relu.fit(X_train_norm, y_train_cat, epochs=10, batch_size=32, \n",
    "                               validation_split=0.1, verbose=0)\n",
    "time_relu = time.time() - start_relu\n",
    "loss_relu, acc_relu = model_relu.evaluate(X_test_norm, y_test_cat, verbose=0)\n",
    "print(f\"   Akurasi: {acc_relu:.4f}, Waktu: {time_relu:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08cd4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi perbandingan Sigmoid vs ReLU\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "axes[0].plot(history_sigmoid.history['accuracy'], label='Sigmoid Train', linestyle='-', marker='o')\n",
    "axes[0].plot(history_sigmoid.history['val_accuracy'], label='Sigmoid Val', linestyle='--', marker='o')\n",
    "axes[0].plot(history_relu.history['accuracy'], label='ReLU Train', linestyle='-', marker='s')\n",
    "axes[0].plot(history_relu.history['val_accuracy'], label='ReLU Val', linestyle='--', marker='s')\n",
    "axes[0].set_title('Perbandingan Accuracy: Sigmoid vs ReLU')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot Loss\n",
    "axes[1].plot(history_sigmoid.history['loss'], label='Sigmoid Train', linestyle='-', marker='o')\n",
    "axes[1].plot(history_sigmoid.history['val_loss'], label='Sigmoid Val', linestyle='--', marker='o')\n",
    "axes[1].plot(history_relu.history['loss'], label='ReLU Train', linestyle='-', marker='s')\n",
    "axes[1].plot(history_relu.history['val_loss'], label='ReLU Val', linestyle='--', marker='s')\n",
    "axes[1].set_title('Perbandingan Loss: Sigmoid vs ReLU')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65eac8",
   "metadata": {},
   "source": [
    "## 6. Ringkasan Hasil Eksperimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38548c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RINGKASAN HASIL EKSPERIMEN\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ“Š RINGKASAN HASIL EKSPERIMEN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Buat tabel perbandingan\n",
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    'Model': [\n",
    "        'Baseline (128-64, ReLU)',\n",
    "        'Exp 1: 256-128 neuron',\n",
    "        'Exp 2: 3 Hidden Layer',\n",
    "        'Exp 3a: Sigmoid',\n",
    "        'Exp 3b: ReLU'\n",
    "    ],\n",
    "    'Hidden Layers': ['2', '2', '3', '2', '2'],\n",
    "    'Neurons': ['128-64', '256-128', '256-128-64', '128-64', '128-64'],\n",
    "    'Activation': ['ReLU', 'ReLU', 'ReLU', 'Sigmoid', 'ReLU'],\n",
    "    'Akurasi (%)': [\n",
    "        f\"{acc*100:.2f}\",\n",
    "        f\"{acc_exp1*100:.2f}\",\n",
    "        f\"{acc_exp2*100:.2f}\",\n",
    "        f\"{acc_sigmoid*100:.2f}\",\n",
    "        f\"{acc_relu*100:.2f}\"\n",
    "    ],\n",
    "    'Waktu (s)': [\n",
    "        f\"{training_time:.2f}\",\n",
    "        f\"{time_exp1:.2f}\",\n",
    "        f\"{time_exp2:.2f}\",\n",
    "        f\"{time_sigmoid:.2f}\",\n",
    "        f\"{time_relu:.2f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“ KESIMPULAN\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. JUMLAH NEURON:\n",
    "   - Menambah neuron (256-128) dapat meningkatkan kapasitas model\n",
    "   - Terlalu banyak neuron bisa menyebabkan overfitting dan waktu training lebih lama\n",
    "\n",
    "2. JUMLAH HIDDEN LAYER:\n",
    "   - 3 hidden layer memberikan representasi fitur yang lebih dalam\n",
    "   - Namun juga meningkatkan kompleksitas dan waktu training\n",
    "\n",
    "3. FUNGSI AKTIVASI (Sigmoid vs ReLU):\n",
    "   - ReLU umumnya lebih cepat konvergen dan mencapai akurasi lebih tinggi\n",
    "   - Sigmoid memiliki masalah vanishing gradient pada jaringan dalam\n",
    "   - ReLU lebih direkomendasikan untuk hidden layer\n",
    "\n",
    "4. REKOMENDASI:\n",
    "   - Untuk MNIST, model dengan 2-3 hidden layer dan ReLU sudah cukup baik\n",
    "   - Akurasi > 97% dapat dicapai dengan arsitektur sederhana\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
